#!/bin/bash
# WARNING: This script causes increments of osdmap epochs for every set-command, which might have
#          unintended side effects. See ceph-user cases "constant increase in osdmap epoch" at
#          https://www.spinics.net/lists/ceph-users/msg84810.html and
#          "failed to load OSD map for epoch 2898146, got 0 bytes" at
#          https://www.spinics.net/lists/ceph-users/msg84485.html

health="$(ceph health --format json-pretty | jq -r ".status")"

[[ "$health" = "HEALTH_OK" ]] || {
	echo "ceph not healthy (status: $health), exiting"
	exit
}

sleep "$((1 + $RANDOM % 29))"
while (( ${#@} )) ; do
	scrub_min_interval="$(ceph osd pool get "$1" scrub_min_interval --format json-pretty | jq -r .scrub_min_interval)"
	if [[ -n "$scrub_min_interval" ]]; then
		if (( scrub_min_interval % 10 )); then
			ceph osd pool set "$1" scrub_min_interval $(( (scrub_min_interval/10)*10 ))
		else
			ceph osd pool set "$1" scrub_min_interval $(( scrub_min_interval+5 ))
			sleep 1
			ceph osd pool set "$1" scrub_min_interval $(( (scrub_min_interval/10)*10 ))
		fi
	fi
	shift
done
